# ğŸï¸ AI 1 Billion Row Challenge Benchmark

> **Who writes the fastest Go code?** A face-off between AI models tackling the [One Billion Row Challenge](https://github.com/gunnarmorling/1brc).

## ğŸ“‹ The Challenge

The goal is simple but heavy: process a massive text file containing **1,000,000,000 rows** of temperature measurements and calculate the min, mean, and max temperature for each weather station.

**Input:** `Hamburg;12.0` (x 1 Billion)  
**Output:** `{Abha=5.0/18.0/27.4, Abidjan=15.7/26.0/34.1, ...}`

## ğŸ¤– The Contestants

We test two variations for each model:
1.  **Raw Prompt**: The model is given the standard challenge description.
2.  **With Hints**: The model is nudged to use advanced techniques (mmap, SIMD, concurrency, etc.).

| Directory                | Model        | Hinted? | Description                        |
|--------------------------|--------------|---------|------------------------------------|
| `go-haiku-4.5`          | Haiku 4.5   | âŒ      | Standard implementation.           |
| `go-gemini3`             | Gemini 3     | âŒ      | Standard implementation.           |
| `go-gemini3-with-hint`   | Gemini 3     | âœ…      | Prompted to use OS/Kernel features.|
| `go-opus4.5`             | Opus 4.5     | âŒ      | Standard implementation.           |
| `go-opus4.5-with-hint`   | Opus 4.5     | âœ…      | Prompted to use OS/Kernel features.|
| `go-qwen`                | Qwen         | âŒ      | Standard implementation.           |
| `go-qwen-with-hint`      | Qwen         | âœ…      | Prompted to use OS/Kernel features.|

## ğŸš€ Getting Started

### Prerequisites
- **Go** (1.24+)
- **Python 3** (for scripts)

### 1. Generate Data
First, you need the 1 billion row dataset. Be warned: this creates a **~13GB** file.

```bash
# Generate 1 Billion rows (takes a while)
python3 create_measurements.py 1_000_000_000
```

For quicker testing during development, you can generate smaller datasets:
```bash
# Generate 10 Million rows
python3 create_measurements.py 10_000_000
```

### 2. Run the Benchmark
Use the runner script to build and benchmark all implementations.

```bash
# Run on the generated file (defaults to data/medium.txt if not specified)
python3 run_all.py data/measurements.txt --runs 3
```

## ğŸ“‚ Project Structure

- `create_measurements.py`: Script to generate the massive dataset.
- `run_all.py`: Benchmark runner and verifier.
- `PROMPT.md`: The base system prompt used for the "Raw" implementations.
- `PROMPT_WITH_HINTS.md`: The prompt containing performance hints.
- `data/`: Stores the measurement files.
- `go-*/`: The various implementations generated by AI.

## ğŸ“Š Results

**Latest Benchmark Run:**

| Implementation | Input | Time (avg) |
|---|---|---|
| go-opus4.5 | medium.tx | t 177.1ms |
| go-haiku-4.5 | medium.tx | t 184.8ms |
| go-gemini3-with-hint | medium.tx | t 184.9ms |
| go-opus4.5-with-hint | medium.tx | t 189.2ms |
| go-gemini3 | medium.tx | t 201.9ms |
| go-gpt5.1 | medium.tx | t 239.2ms |
| go-qwen | medium.tx | t 247.6ms |
| go-haiku-4.5-with-hi | nt medium. | txt 250.1ms |
| go-qwen-with-hint | medium.tx | t 262.5ms |
| go-gpt5.1-with-hint | medium.tx | t 298.3ms |

---
*Based on the original [1BRC by Gunnar Morling](https://github.com/gunnarmorling/1brc).*

